apiVersion: batch/v1
kind: CronJob
metadata:
  name: bifrost-backup
  namespace: bifrost-system
  labels:
    app: bifrost-backup
spec:
  schedule: "0 2 * * *"  # Daily at 2 AM
  concurrencyPolicy: Forbid
  successfulJobsHistoryLimit: 3
  failedJobsHistoryLimit: 3
  jobTemplate:
    spec:
      template:
        spec:
          serviceAccountName: bifrost-backup
          containers:
          - name: backup
            image: bifrost/backup-tools:latest
            command:
            - /scripts/backup-script.sh
            env:
            - name: BACKUP_S3_BUCKET
              valueFrom:
                secretKeyRef:
                  name: backup-config
                  key: s3-bucket
                  optional: true
            - name: AWS_ACCESS_KEY_ID
              valueFrom:
                secretKeyRef:
                  name: backup-config
                  key: aws-access-key-id
                  optional: true
            - name: AWS_SECRET_ACCESS_KEY
              valueFrom:
                secretKeyRef:
                  name: backup-config
                  key: aws-secret-access-key
                  optional: true
            - name: SLACK_WEBHOOK_URL
              valueFrom:
                secretKeyRef:
                  name: backup-config
                  key: slack-webhook-url
                  optional: true
            volumeMounts:
            - name: backup-scripts
              mountPath: /scripts
            - name: backup-storage
              mountPath: /opt/bifrost/backups
            resources:
              requests:
                memory: "128Mi"
                cpu: "100m"
              limits:
                memory: "256Mi"
                cpu: "200m"
          volumes:
          - name: backup-scripts
            configMap:
              name: backup-scripts
              defaultMode: 0755
          - name: backup-storage
            persistentVolumeClaim:
              claimName: backup-storage-pvc
          restartPolicy: OnFailure
---
apiVersion: v1
kind: ConfigMap
metadata:
  name: backup-scripts
  namespace: bifrost-system
data:
  backup-script.sh: |
    #!/bin/bash
    set -euo pipefail
    
    BACKUP_DIR="/opt/bifrost/backups"
    RETENTION_DAYS=30
    TIMESTAMP=$(date +%Y%m%d_%H%M%S)
    BACKUP_NAME="bifrost-backup-${TIMESTAMP}"
    BACKUP_PATH="${BACKUP_DIR}/${BACKUP_NAME}"
    
    mkdir -p "${BACKUP_PATH}"
    
    log() {
        echo "[$(date '+%Y-%m-%d %H:%M:%S')] $1" | tee -a "${BACKUP_PATH}/backup.log"
    }
    
    # Backup ConfigMaps and Secrets
    kubectl get configmap -n bifrost-system -o yaml > "${BACKUP_PATH}/configmaps.yaml"
    kubectl get secret -n bifrost-system -o yaml > "${BACKUP_PATH}/secrets.yaml"
    kubectl get deployment -n bifrost-system -o yaml > "${BACKUP_PATH}/deployments.yaml"
    kubectl get service -n bifrost-system -o yaml > "${BACKUP_PATH}/services.yaml"
    kubectl get ingress -n bifrost-system -o yaml > "${BACKUP_PATH}/ingress.yaml"
    kubectl get hpa -n bifrost-system -o yaml > "${BACKUP_PATH}/hpa.yaml"
    kubectl get pvc -n bifrost-system -o yaml > "${BACKUP_PATH}/pvc.yaml"
    
    # Backup Redis data
    kubectl exec -n bifrost-system redis-0 -- redis-cli BGSAVE
    sleep 10
    kubectl cp bifrost-system/redis-0:/data/dump.rdb "${BACKUP_PATH}/redis-dump.rdb"
    
    # Get application logs
    kubectl logs -n bifrost-system -l app=bifrost-gateway --tail=10000 > "${BACKUP_PATH}/gateway-logs.txt"
    kubectl logs -n bifrost-system -l app=prometheus --tail=10000 > "${BACKUP_PATH}/prometheus-logs.txt"
    kubectl logs -n bifrost-system -l app=redis --tail=10000 > "${BACKUP_PATH}/redis-logs.txt"
    
    # Create archive
    cd "${BACKUP_DIR}"
    tar -czf "${BACKUP_NAME}.tar.gz" "${BACKUP_NAME}"
    sha256sum "${BACKUP_NAME}.tar.gz" > "${BACKUP_NAME}.tar.gz.sha256"
    rm -rf "${BACKUP_NAME}"
    
    # Upload to S3 if configured
    if [ -n "${BACKUP_S3_BUCKET:-}" ]; then
        aws s3 cp "${BACKUP_DIR}/${BACKUP_NAME}.tar.gz" "s3://${BACKUP_S3_BUCKET}/bifrost-backups/"
        aws s3 cp "${BACKUP_DIR}/${BACKUP_NAME}.tar.gz.sha256" "s3://${BACKUP_S3_BUCKET}/bifrost-backups/"
    fi
    
    # Send notification if configured
    if [ -n "${SLACK_WEBHOOK_URL:-}" ]; then
        curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"Bifrost Backup SUCCESS: ${BACKUP_NAME} completed successfully\"}" \
            "${SLACK_WEBHOOK_URL}"
    fi
    
    # Clean old backups
    find "${BACKUP_DIR}" -name "bifrost-backup-*.tar.gz" -mtime +${RETENTION_DAYS} -delete
    find "${BACKUP_DIR}" -name "bifrost-backup-*.tar.gz.sha256" -mtime +${RETENTION_DAYS} -delete
    
    log "Backup completed successfully: ${BACKUP_NAME}.tar.gz"
---
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: backup-storage-pvc
  namespace: bifrost-system
spec:
  accessModes:
  - ReadWriteOnce
  resources:
    requests:
      storage: 50Gi
---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: bifrost-backup
  namespace: bifrost-system
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: bifrost-backup
  namespace: bifrost-system
rules:
- apiGroups: [""]
  resources: ["configmaps", "secrets", "services", "persistentvolumeclaims"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods", "pods/log"]
  verbs: ["get", "list"]
- apiGroups: [""]
  resources: ["pods/exec"]
  verbs: ["create"]
- apiGroups: ["apps"]
  resources: ["deployments", "statefulsets"]
  verbs: ["get", "list"]
- apiGroups: ["networking.k8s.io"]
  resources: ["ingresses"]
  verbs: ["get", "list"]
- apiGroups: ["autoscaling"]
  resources: ["horizontalpodautoscalers"]
  verbs: ["get", "list"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: bifrost-backup
  namespace: bifrost-system
subjects:
- kind: ServiceAccount
  name: bifrost-backup
  namespace: bifrost-system
roleRef:
  kind: Role
  name: bifrost-backup
  apiGroup: rbac.authorization.k8s.io